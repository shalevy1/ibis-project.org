{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Analytics Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "import os\n",
    "hdfs_port = os.environ.get('IBIS_WEBHDFS_PORT', 50070)\n",
    "hdfs = ibis.hdfs_connect(host='impala', port=hdfs_port)\n",
    "con = ibis.impala.connect(host='impala', database='ibis_testing',\n",
    "                          hdfs_client=hdfs)\n",
    "ibis.options.interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency tables\n",
    "\n",
    "Ibis provides the `value_counts` API, just like pandas, for computing a frequency table for a table column or array expression. You might have seen it used already earlier in the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   o_orderpriority    count\n",
       "0         3-MEDIUM  1194959\n",
       "1         1-URGENT  1201581\n",
       "2  4-NOT SPECIFIED  1199524\n",
       "3           2-HIGH  1202490\n",
       "4            5-LOW  1202661"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineitem = con.table('tpch_lineitem')\n",
    "orders = con.table('tpch_orders')\n",
    "\n",
    "items = (orders.join(lineitem, orders.o_orderkey == lineitem.l_orderkey)\n",
    "         [lineitem, orders])\n",
    "\n",
    "items.o_orderpriority.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be customized, of course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   o_orderpriority    nrows         total $\n",
       "0         3-MEDIUM  1194959  45698023582.03\n",
       "1         1-URGENT  1201581  45969422546.87\n",
       "2  4-NOT SPECIFIED  1199524  45820992304.35\n",
       "3           2-HIGH  1202490  46033003696.98\n",
       "4            5-LOW  1202661  46055868770.97"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = (items.group_by(items.o_orderpriority)\n",
    "        .aggregate([items.count().name('nrows'),\n",
    "                    items.l_extendedprice.sum().name('total $')]))\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning and histograms\n",
    "\n",
    "\n",
    "Numeric array expressions (columns with numeric type and other array expressions) have `bucket` and `histogram` methods which produce different kinds of binning. These produce category values (the computed bins) that can be used in grouping and other analytics.\n",
    "\n",
    "Let's have a look at a few examples\n",
    "\n",
    "I'll use the `summary` function to see the general distribution of lineitem prices in the order data joined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     count  nulls     min        max              sum      mean  \\\n",
       "0  6001215      0  901.00  104949.50  229577310901.20  38255.13   \n",
       "\n",
       "   approx_nunique  \n",
       "0          868550  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.l_extendedprice.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright then, now suppose we want to split the item prices up into some buckets of our choosing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 5000, 10000, 50000, 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bucket` function creates a bucketed category from the prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed = items.l_extendedprice.bucket(buckets).name('bucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the value counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  bucket    count\n",
       "0    2.0  3329905\n",
       "1    NaN     4122\n",
       "2    0.0   352843\n",
       "3    3.0  1893650\n",
       "4    1.0   420695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buckets we wrote down define 4 buckets numbered 0 through 3. The `NaN` is a pandas `NULL` value (since that's how pandas represents nulls in numeric arrays), so don't worry too much about that. Since the bucketing ends at 100000, we see there are 4122 values that are over 100000. These can be included in the bucketing with `include_over`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  bucket    count\n",
       "0      2  3329905\n",
       "1      0   352843\n",
       "2      3  1893650\n",
       "3      1   420695\n",
       "4      4     4122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketed = (items.l_extendedprice\n",
    "            .bucket(buckets, include_over=True)\n",
    "            .name('bucket'))\n",
    "bucketed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bucketed` object here is a special **_category_** type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category(cardinality=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketed.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category values can either have a known or unknown **_cardinality_**. In this case, there's either 4 or 5 buckets based on how we used the `bucket` function.\n",
    "\n",
    "Labels can be assigned to the buckets at any time using the `label` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       bucket_name bucket    count\n",
       "0        0 to 5000      0   352843\n",
       "1    5000 to 10000      1   420695\n",
       "2   10000 to 50000      2  3329905\n",
       "3  50000 to 100000      3  1893650\n",
       "4      Over 100000      4     4122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_counts = bucketed.value_counts()\n",
    "\n",
    "labeled_bucket = (bucket_counts.bucket\n",
    "                  .label(['0 to 5000', '5000 to 10000', '10000 to 50000',\n",
    "                          '50000 to 100000', 'Over 100000'])\n",
    "                  .name('bucket_name'))\n",
    "\n",
    "expr = (bucket_counts[labeled_bucket, bucket_counts]\n",
    "        .sort_by('bucket'))\n",
    "expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, huh?\n",
    "\n",
    "`histogram` is a linear (fixed size bin) equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  hist_bin   min   max  count\n",
       "0        0   0.0   0.0    730\n",
       "1        1  10.1  10.1    730\n",
       "2        2  20.2  20.2    730\n",
       "3        3  30.3  30.3    730\n",
       "4        4  40.4  40.4    730\n",
       "5        5  50.5  50.5    730\n",
       "6        6  60.6  60.6    730\n",
       "7        7  70.7  70.7    730\n",
       "8        8  80.8  80.8    730\n",
       "9        9  90.9  90.9    730"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = con.table('functional_alltypes')\n",
    "\n",
    "d = t.double_col\n",
    "\n",
    "tier = d.histogram(10).name('hist_bin')\n",
    "expr = (t.group_by(tier)\n",
    "        .aggregate([d.min(), d.max(), t.count()])\n",
    "        .sort_by('hist_bin'))\n",
    "expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering in aggregations\n",
    "\n",
    "\n",
    "Suppose that you want to compute an aggregation with a subset of the data for _only one_ of the metrics / aggregates in question, and the complete data set with the other aggregates. Most aggregation functions are thus equipped with a `where` argument. Let me show it to you in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  color  # rows total  # selected     total  selected total\n",
       "0  blue          4380         730  199071.0         51611.0\n",
       "1   red          2920        1460  132714.0         58984.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = con.table('functional_alltypes')\n",
    "\n",
    "d = t.double_col\n",
    "s = t.string_col\n",
    "\n",
    "cond = s.isin(['3', '5', '7'])\n",
    "\n",
    "metrics = [t.count().name('# rows total'), \n",
    "           cond.sum().name('# selected'),\n",
    "           d.sum().name('total'),\n",
    "           d.sum(where=cond).name('selected total')]\n",
    "\n",
    "color = (t.float_col\n",
    "         .between(3, 7)\n",
    "         .ifelse('red', 'blue')\n",
    "         .name('color'))\n",
    "\n",
    "t.group_by(color).aggregate(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
